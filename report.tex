%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages
\usepackage{graphicx}
\graphicspath{ {images/} }
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template

\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	
\normalfont \normalsize 
\textsc{University of the Witwatersrand} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Parallel Computing: Image noise filtering project \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Liam Pulles} % Your name

\date{\normalsize September 30, 2016} % Today's date or a custom date

\begin{document}

\maketitle % Print the title

\section{Introduction}
\subsection{Problem statement}
\subsection{Proposed solution overview}
\subsection{Background Theory}

\section{Solution technicalities}
\subsection{Serial Implementation}
The serial implementation works as follows:
 - An image is loaded into memory (a pointer to BMP).
 - The matrix structure is created (we've made a few standard 5x5 and 3x3 matrices).
 - The covolution function is called.
 - The convolution function makes a blank output BMP* structure with the same dimensions as the source image for storing the calculated pixels. 
 - The covolution function calls the kernel function for each pixel, using two nested for loops.
 - The kernel function calculates the kernel for a pixel using the edge extrapolation function, the matrix sturucture, and the source image. The final calculation for the pixel is stored in the output BMP* structure directly for speed.
 - Once the whole covolution is complete, the program writes a new file with the filtered image.
 
\subsection{Parallel Implementation}
The parallel implementation differs from the serial implementation in that instead of the master thread (the serial program) iterating through each pixel, the parallel implementation has several threads going through different pixels at the same time.

This is achieved by use of an omp for loop structure. Each iteration of the outer for loop calculates the kernel for a (image height)x([matrix width]x2) sized block of the image (See diagram x) (Note that the final chunk is truncated to fit with the width of the image).  There are a few reasons for this choice of parallelisation:
- We want to to keep the number of chunks for threads to process low so as to reduce communication time, but we also want there to be enough chunks so that threads that execute their chunks quickly can do something useful while waiting for other threads.
- We want the dimensions of the chunks to minimize potential contention between threads, specifically when we are calculating the kernel for two seperate pixels which are in kernel dimension range (this would result in both the kernel calculations needing to contend for the same pixels for their own calculation, see diagram x). Assuming the image is reasonably sized, using (matrix width)*2 width chunks will nearly always keep the kernel calculations far enough away from each other at each moment of execution, even when one thread is running faster than the others. For a 5x5 kernel, a thread would have to have done more than 5 columns of the image before one thread had done a single column for there to be contention issues in this regard.

Each thread works column by column. We do not create seperate sub images for each thread to use for source and output because it would require splitting overhead at the beginning and joining overhead at the end. It is mentioned in the EasyBMP documentation (Reference) that the pixel data is stored internally as a 2d array. We also know that this must be stored on the heap, since it has to do deal with varying sized images (and thus, varying sized 2d arrays). What we don't know is whether the image is stored row first or column first. 

It is thus also difficult to say what contention issues might arise in the current implementation, specifically the contention that arises when threads read from the same source image in memory at approximately the same time, and write to the same output image at approximately the same time. Will contention on the cache line arise from reading the same row, or the same column?

It is important to note however that the above scenario is not likely to occur often for the duration of the image convolution processing. Threads, operating on identically sized chunks of the image (excluding the final chunk), will likely take different times to finish, and will be at different stages of their chunk with respect to other threads at most moments of execution. This is mainly because of the uncertain scheduling of the operating system, but also because there are slight differences in the complexity of the calculations for various chunks.

Specifically, the chunk at the beginning will invlolve calculations that extend out the left side of the image, resulting in different processing inside the edge extrapolation function than a chunk not on the side, ultimatelly resulting in differing execution times for the threads. This will slightly desync the left (or alternatively the right) thread with the other thread with respect to the chunks.

Suppose the threads were perfectly scheduled, i.e. whenever a thread is being executed every other thread is also being executed. Also ignoring the point in the paragraph above - the threads would all do their calculation in complete synchronization. I.e. they would all work on pixels in the same row but in differnet columns at the same time before progressing to the next row, etc. So the row is in sync.

Now suppose that the pixels are stored row first - i.e. one thread would have to wait for the other thread to finish storing it's pixel before it can store it's own pixel. Then the two threads will become desynced with respect to that row in the image. But if the two threads now continue to do their calculations, they will not likely run into that contention again because they will be likely operating on seperate rows at each step from then on (they will, by design, be operating on different columns).

Thus, although initial contention here is quite possible, it will not likely be a recurring issue as a result of the threads being continually desynced from another with respect to row and column in the image. Note that rows may become resynced (briefly) during the execution of the program as a result of some rows already being in shared cache due to leading threads having fetched them for their calculation - the leading thread will be slowed down as a result of having to be the thread that fetches the rows from RAM all the time and the other threads will catch up. This is obviously hardware dependent.

If infact the image is stored column first however, then there really is no source of contention here at all since each thread is only accessed and written to by one thread at a time. Infact, since the threads work column by column, this could very well result in whole columns being in cache for each thread, thus reducing waiting time for tht columns processing and the image as a whole.

In any case, there IS a marked speed improvement with our parallel implementation as will be seen momentarily.
\section{Results analysis}

\section{Conclusion}

\end{document}