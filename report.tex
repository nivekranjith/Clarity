%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages
\usepackage{graphicx}
\usepackage{float}
%\usepackage{cite}
%\usepackage[backend=bibtex]{biblatex}
\graphicspath{ {} }
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template

\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

%\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	
\normalfont \normalsize 
\textsc{University of the Witwatersrand} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Parallel Computing: Image noise filtering project \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Liam Pulles\\
		Jadon Manilall - 815050} % Your name

\date{\normalsize September 30, 2016} % Today's date or a custom date

\begin{document}

\maketitle % Print the title

\section{Introduction}
\subsection{Problem statement}
\subsection{Proposed solution overview}
\subsection{Background Theory}

\section{Solution technicalities}
\subsection{Serial Implementation}
The serial implementation works as follows:
\begin{enumerate}
\item An image is loaded into memory (a pointer to BMP).
\item The matrix structure is created (we've made a few standard 5x5 and 3x3 matrices).
\item The covolution function is called.
\item The convolution function makes a blank output BMP* structure with the same dimensions as the source image for storing the calculated pixels. 
\item The covolution function calls the kernel function for each pixel, using two nested for loops.
\item The kernel function calculates the kernel for a pixel using the edge extrapolation function, the matrix sturucture, and the source image. The final calculation for the pixel is stored in the output BMP* structure directly for speed.
\item Once the whole covolution is complete, the program writes a new file with the filtered image.
\end{enumerate}
  
\subsection{Parallel Implementation}
The parallel implementation differs from the serial implementation in that instead of the master thread (the serial program) iterating through each pixel, the parallel implementation has several threads going through different pixels at the same time.

This is achieved by use of an omp for loop structure. We use dynamic scheduling to accomodate for potential differences in complexity in regions of the image. Each iteration of the outer for loop calculates the kernel for a (image height)x([matrix width]x2) sized chunk of the image (See figure \ref{chunks}) (Note that the final chunk is truncated to fit with the width of the image).  There are a few reasons for this choice of task decomposition:

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.25]{"Chunks"}
	\caption{The decomposition of the workload of the image into chunks.}
        \label{chunks}
\end{figure}

\begin{itemize}
\item We want to to keep the number of chunks for threads to process low so as to reduce unproductive inter-thread communication time, but we also want there to be enough chunks so that threads that execute their chunks quickly can still have something useful to do while waiting for other threads.
\item We want the dimensions of the chunks to minimize potential contention between threads, specifically when we are calculating the kernel for two seperate pixels which are in kernel dimension range (this would result in both the kernel calculations needing to contend for the same pixels for their own calculation, see figure \ref{kernels}). Assuming the image is reasonably sized, using (matrix width)*2 width chunks will nearly always keep the kernel calculations far enough away from each other at each moment of execution, even when one thread is running faster than the others. For a 5x5 kernel, a thread would have to have done more than 5 columns of the image before one thread had done a single column for there to be contention issues in this regard.
\end{itemize}


\begin{figure}[H]
	\centering
	\includegraphics[scale=0.2]{"Kernels"}
	\caption{An example of contention with nearby simultaneous kernel calculations. The purple region represents potentially contested pixels.}
        \label{kernels}
\end{figure}
  
Each thread works column by column. We do not create seperate sub images for each thread to use for source and output because it would require splitting overhead at the beginning and joining overhead at the end. It is mentioned in the EasyBMP documentation (EasyBMP Manual 1.06, pg. 16) that the RGBApixel pointers are stored internally as a 2d array. We also know that this must be stored on the heap, since it has to do deal with varying sized images (and thus, varying sized 2d arrays). Finally, we can deduce that since the size of the array is width x column that these 2d arrays store arrays of rows (the x component of the image).

So what about the contention that arises when threads read from the same source image in memory at approximately the same time, and write to the same output image at approximately the same time. Will contention on the cache line arise from reading/writing the same row?

We compared two version of the parallel implementation - one which sequentially accessed by row and one which sequentially accessed by column. The difference in execution time was negligible.

Why is this? We believe it is because the 2d array stores pixel POINTERS.

Suppose there is contention between 2 threads trying to access far away pixels on the same row, and - we shall presume for argument's sake - the same cache line. Then one thread will have to wait while the other gets the pointer data (which is of size int). But after that contention, mofiying or reading to that RGBApixel - which forms the vast bulk of the process of modifying a pixel - will be independent of modifyng or reading any other RGBApixel, since it is a pointer and can exist anywhere in the heap and thus on seperate cache lines.

So since the delay caused by the contention is so small, it has an almost zero sum effect on the toal execution time. The number of contentions also becomes less over time, as once a contention does arise, one of the threads will move forward while another has to wait. So ultimately, the threads will often be working on both different rows and different columns anyway.


\section{Results analysis}

\subsection{About the code}
\begin{itemize}

\item \textbf{To compile}  : make
\item \textbf{To Run}
	\subitem Serial Version : ./main source.bmp output.bmp \textbf{s} \\  
	\subitem Parallel Version : ./main source.bmp output.bmp \textbf{p} \\
	
\end{itemize}

\subsection{About the Hardware}

\begin{itemize}
\item{Core i5 4670k \\}
\item{3.4 Ghz \\}
\item{Quad Core \\}
\end{itemize}




\subsection{Analysis}
The following results were obtained by using a 5x5 Gaussian blur kernal matrix on the image set stored in TestBMP.\\
Each .bmp image has a resoloution of 2560x1440 px resulting in a size of 11.1Mb per image. Now, Because of this large resoloution each image was processed 10 times and the average of that processing time was recoreded to promote more accurate results.\\


We should also note that the time taken to read from and write to files have been excluded.\\


The following table illustrates the parallel and serial processing time for each image.\\

\begin{center}

\begin{tabular}{||c |c |c |c ||}
\hline
\textbf{Image Used} & \textbf{Serial Time(S)} & \textbf{Parallel Time(S)} & \textbf{Difference(S)} \\[0.5ex]
\hline \hline

1.bmp & 3.69834 & 1.03163 & 2.66671 \\
2.bmp & 3.67825 & 1.02016 & 2.65809\\
3.bmp & 3.68039 & 1.02509 & 2.6553\\
4.bmp & 3.68526 & 1.03562 & 2.64964\\
5.bmp & 3.66079 & 1.03453 & 2.62626\\
6.bmp & 3.67016 & 1.0301 & 2.64006\\
7.bmp & 3.678 & 1.03763 & 2.64037\\
8.bmp & 3.68696 & 1.03739  & 2.64957\\
9.bmp & 3.67905 & 1.03905 & 2.64\\
10.bmp & 3.67905 & 1.09719 & 2.58186\\[1ex]

\hline

\end{tabular}

\end{center}

Using the above table we can see that on average our parallel implentation lowers our processing time by 2.640786 seconds.\\

Moreover, If we denote the average serial time by \textbf{Ts} and denote the average parallel time by \textbf{Tp}, where \\
\textbf{Ts} = 3.679625 and \\
\textbf{Tp} = 1.038839 \\
We can caluclate the Average Speed Up$(S_a)$ for our solution by using the formula
\begin{equation}
\begin{split}
S_a &= \frac{Ts}{Tp}  \\
	&=\frac{3.679625}{1.038839}  \\
	&=3.5420551
\end{split}
\end{equation}\\
More over, We can calculate our effeicency(E) using 
\begin{equation}
\begin{split}
E &= \frac{S_a}{p}
\end{split}
\end{equation}\\
Here, p represents the number of processing elements involved. In our case, We've used p = 4, Since 4 processors is optimal for current hardware situation\\
Hence the Above becomes,

\begin{equation}
\begin{split}
E &= \frac{3.5420551}{4}\\
	&= 0.885514
\end{split}
\end{equation}


The reason for this increase in performance is explaned in section 2.2\\

The following diagram is a graph which represents the above table in a visual way...\\


\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{"graph2"}
	\caption{Serial Vs Parallel (Lower is better)}
        \label{graph1}
\end{figure}


Here, using the above graph it becomes easier to see that our parallel implemtation greatly out performs our serial implentation everytime.








\section{Conclusion}

\end{document}